At the moment, big data is a big deal. Technology developed in the past few decades means that more information than ever before is being collected. Management, storage and processing capabilities have advanced rapidly in recent years. There is a huge amount of information and potential in this data. 

In many fields, one of the biggest buzzwords is machine learning. Broadly, machine learning consists of techniques, algorithms, etc., which allow us to `learn' from the data. Machine learning discovers patterns and makes predictions, with minimal conditions. Given that the world has more data than most people know how to handle, computers end up doing most of the work and discovery, making understanding data and utilizing it to its fullest potential much easier.

Economic modelling stands to benefit immensely from big data and the ideas in machine learning. More data can provide a clearer picture of the world, and should contribute to a clearer understanding of its dynamics and complexities. However, while data has become increasingly available, the implementation of the theory regarding how to actually use all this data is still catching up. The field of economics is still figuring out how to exploit big data. 

The reason why economics hasn't enthusiastically `jumped on the machine learning train' lies in the fact that econometrics is fundamentally concerned with inference and machine learning is primarily related to finding patterns and making predictions. This means that the objective in machine learning algorithms is for example to minimize the prediction error, not to necessarily understand how the predictions are being formed. For economists however, there are three main uses for economic modelling: forecasting, policy and modelling. In the modelling and policy worlds economists are concerned with what drives a particular variable. Standard econometrics allows economists to test models, draw conclusions, and provide information on the underlying process driving a particular variable. This is valuable because it then allows a researcher, government, business, etc., to understand the impact of changing a `driving force' on a given variable. 

For economic modellers and policy makers an important question arises. How can we use big data to our advantage without foregoing inference? This is where automatic model selection becomes a very useful tool.

As its name would suggest, automatic model selection is using algorithms to automatically select models. Very generally, model selection algorithms work to find the `best' model (according to a particular set of criteria, objective function, etc.) of a particular dependent variable, given a set of potential explanatory variables. This is incredibly useful; the computer is performing tests and doing the work that a researcher might normally do herself. 

It is important to point out that there are differences between model selection and forecasting. The goal of model selection is to select a model which is as close to the data generating process (DGP) as possible.  The goal of forecasting is to produce models which have minimal prediction error. Because the world is non-stationary, full of correlations and structural breaks these two goals do not necessarily coincide. Standard machine learning techniques can generally only be applied to forecasting and prediction problems, which highlights the need for techniques focussed on the model selection problem to be developed and analyzed. 

The goal of this thesis is to study, evaluate and compare the performance of model selection algorithms under different states of nature. The state of nature refers to the correlation structure of the variables being considered in the model. Three different algorithms are tested: Autometrics, the Lasso and Bayesian Structural Time Series. This is the first time a comparison between these three algorithms has been undertaken. While studies do exist which feature pairwise comparison, these are rare and do not consider the various states of nature considered here. Additionally, the studies that do exist do not endeavor to compare the algorithms using the metrics used here and tend to focus on the predictive power (i.e. accuracy of forecasts) of model selection algorithms. In this thesis Monte Carlo simulations are used so the DGP is known, which allows the algorithms to be compared using metrics which are more relevant to the model selection problem. %\cite{lassovauto}

The thesis is structured as follows: Chapter 2 describes the algorithms included in this study, Chapter 3 tests the algorithms in the context of Monte Carlo simulations, Chapter 4 is an empirical application of automatic model selection building off the Google Flu Trends application and Chapter 5 concludes. 


